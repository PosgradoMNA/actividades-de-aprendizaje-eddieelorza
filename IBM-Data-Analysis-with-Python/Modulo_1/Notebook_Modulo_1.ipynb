{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/PosgradoMNA/actividades-de-aprendizaje-eddieelorza/blob/main/Modulo_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF7C6SXm3Wu0"
      },
      "source": [
        "\n",
        "# **MODULO 1** | Data Analysis with Python (IBM)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNChtYnnCEgh"
      },
      "source": [
        "**EDDIE G. ELORZA RUIZ | A01793547**\n",
        "\n",
        ">Materia: Ciencia y analÃ­tica de datos (Gpo 10)\n",
        "\n",
        ">Profesor Titular: Jobish Vallikavungal\n",
        "\n",
        ">Profesor Tutor: Victoria Guerrero Orozco"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrG6_sMs6G_9"
      },
      "source": [
        "#**Why Data Analysis?**\n",
        "* Data is everywhere\n",
        "* Data Analysis/Data Science helps us answer questions from data.\n",
        "* Data analysis plays an importan role in: \n",
        " * Discovering useful information\n",
        " * Anwering questions\n",
        " * Predicting future or the unknown\n",
        "\n",
        "#**Understanding the Data**\n",
        "#**Scientifics Computing Libraries in Python**\n",
        "* Pandas (Data scructures & tools)\n",
        "* NumPy (Arrays & matrices)\n",
        "* SciPy (Integrals, solving differential equations, optimization)\n",
        "\n",
        "#**Visualitation Libraries in Python**\n",
        "* Matplotlib (plots & graphs, most popular)\n",
        "* Seaborn (plots: heat maps, time series, violin plots)\n",
        "\n",
        "#**Algorithmic Libraries in Python**\n",
        "* Scikit-learn (Machine Learnning: regression, classification,...)\n",
        "* Statsmodels (Explore data, estimate statistical models, and perform statistical tests.)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sj0cKM1-I_j"
      },
      "source": [
        "<h1 id=\"data_acquisition\">Data Acquisition</h1>\n",
        "<p>\n",
        "There are various formats for a dataset: .csv, .json, .xlsx  etc. The dataset can be stored in different places, on your local machine or sometimes online.<br>\n",
        "\n",
        "In this section, you will learn how to load a dataset into our Jupyter Notebook.<br>\n",
        "\n",
        "In our case, the Automobile Dataset is an online source, and it is in a CSV (comma separated value) format. Let's use this dataset as an example to practice data reading.\n",
        "\n",
        "<ul>\n",
        "    <li>Data source: <a href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data</a></li>\n",
        "    <li>Data type: csv</li>\n",
        "</ul>\n",
        "The Pandas Library is a useful tool that enables us to read various datasets into a dataframe; our Jupyter notebook platforms have a built-in <b>Pandas Library</b> so that all we need to do is import Pandas without installing.\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3djnM7w-4bk"
      },
      "outputs": [],
      "source": [
        "#you are running the lab in your  browser, so we will install the libraries using ``piplite``\n",
        "import piplite\n",
        "import micropip\n",
        "await piplite.install(['pandas'])\n",
        "await piplite.install(['matplotlib'])\n",
        "await piplite.install(['scipy'])\n",
        "await piplite.install(['seaborn'])\n",
        "await micropip.install(['ipywidgets'],keep_going=True)\n",
        "await micropip.install(['tqdm'],keep_going=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SJnPlMYO-Tzz"
      },
      "outputs": [],
      "source": [
        "# import pandas library\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcOFcSu4-5Qc"
      },
      "outputs": [],
      "source": [
        "#This function will download the dataset into your browser \n",
        "\n",
        "from pyodide.http import pyfetch\n",
        "\n",
        "async def download(url, filename):\n",
        "    response = await pyfetch(url)\n",
        "    if response.status == 200:\n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(await response.bytes())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Eg4N5-Z-9Bh"
      },
      "source": [
        "<h2>Read Data</h2>\n",
        "<p>\n",
        "We use <code>pandas.read_csv()</code> function to read the csv file. In the brackets, we put the file path along with a quotation mark so that pandas will read the file into a dataframe from that address. The file path can be either an URL or your local file address.<br>\n",
        "\n",
        "Because the data does not include headers, we can add an argument <code>headers = None</code> inside the <code>read_csv()</code> method so that pandas will not automatically set the first row as a header.<br>\n",
        "\n",
        "You can also assign the dataset to any variable you create.\n",
        "\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgrz8e75_EUy"
      },
      "outputs": [],
      "source": [
        "path = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwDxpObY_Imk"
      },
      "outputs": [],
      "source": [
        "#you will need to download the dataset; if you are running locally, please comment out the following \n",
        "await download(path, \"auto.csv\")\n",
        "path=\"auto.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtvfkiUc_MHl"
      },
      "outputs": [],
      "source": [
        "# Import pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# Read the online file by the URL provides above, and assign it to variable \"df\"\n",
        "\n",
        "df = pd.read_csv(path, header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s62ubVC6_ONk"
      },
      "outputs": [],
      "source": [
        "# show the first 5 rows using dataframe.head() method\n",
        "print(\"The first 5 rows of the dataframe\") \n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbD5afVR_aDQ"
      },
      "source": [
        "<div class=\"alert alert-danger alertdanger\" style=\"margin-top: 20px\">\n",
        "<h1> Question #1: </h1>\n",
        "<b>Check the bottom 10 rows of data frame \"df\".</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sTnmhSs_RwY"
      },
      "outputs": [],
      "source": [
        "df.tail(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmMqzwTW_iND"
      },
      "source": [
        "<h3>Add Headers</h3>\n",
        "<p>\n",
        "Take a look at our dataset. Pandas automatically set the header with an integer starting from 0.\n",
        "</p>\n",
        "<p>\n",
        "To better describe our data, we can introduce a header. This information is available at:  <a href=\"https://archive.ics.uci.edu/ml/datasets/Automobile?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkDA0101ENSkillsNetwork20235326-2021-01-01\" target=\"_blank\">https://archive.ics.uci.edu/ml/datasets/Automobile</a>.\n",
        "</p>\n",
        "<p>\n",
        "Thus, we have to add headers manually.\n",
        "</p>\n",
        "<p>\n",
        "First, we create a list \"headers\" that include all column names in order.\n",
        "Then, we use <code>dataframe.columns = headers</code> to replace the headers with the list we created.\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-eRj4PI_qMv"
      },
      "outputs": [],
      "source": [
        "# create headers list\n",
        "headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
        "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
        "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
        "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]\n",
        "print(\"headers\\n\", headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPG8Kfxg_tvS"
      },
      "outputs": [],
      "source": [
        "#We replace headers and recheck our dataframe:\n",
        "df.columns = headers\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8_-AOCp_wBm"
      },
      "outputs": [],
      "source": [
        "#We need to replace the \"?\" symbol with NaN so the dropna() can remove the missing values:\n",
        "df1=df.replace('?',np.NaN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLi0ru6r_12D"
      },
      "outputs": [],
      "source": [
        "#We can drop missing values along the column \"price\" as follows:\n",
        "df=df1.dropna(subset=[\"price\"], axis=0)\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87_psurN_pl6"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
